{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your libraries:\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Challenge 0 - Load,Query and Create connection of your Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A lot of the times you won't have files already saved in an Excel or CSV file for you to prepare your data, implying that a lot of times you'll be extracting data from a Data Warehouse or Data Lake, majority of times through SQL.\n",
    "#### A couple of times you may want to do some queries on your table in mySQL to get a slight view on what you have in hands,\n",
    "#### so let's simulate that!\n",
    "\n",
    "#### First we'll need to create a database and table in mySQL:\n",
    "\n",
    "##### 1º- Open the austin_weather.sql file in MySQL Workbench and run the script into a desired schema.\n",
    "\n",
    "#### 2º- As we are in mySQL Workbench, we can do some queries there, to get an overview on some characteristics of our data:\n",
    " - a) How many days are recorded in the dataset?\n",
    " - b) What is the day with the Highest Temperature in Fahrenheit (column TempHighF)\n",
    " - c) What is the average Humidity across all days? (column HumidityAvgPercent)\n",
    " - d) Top 10 days, where SeaLevelPressureAvgInches is the highest, knowing DewPointAvgF is higher than 28 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answers below:\n",
    "\n",
    "# a) 1319\n",
    "# b) '2017-07-29'\n",
    "# c) 66.57 Farenheit\n",
    "# d) 30.54"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that you explored a couple of elements in your table, let's bring your table into this jupyter notebook, by creating a Python-SQL connection like you did on MySQL Project!\n",
    "#### In case you need a little refresher check this [link](https://www.dataquest.io/blog/sql-insert-tutorial/).\n",
    "##### 1º - Create a connection using sqlalchemy from python to mysql \n",
    "##### 2º- Load the table into a variable called weather_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  TempHighF  TempAvgF  TempLowF DewPointHighF DewPointAvgF  \\\n",
      "0 2013-12-21         74        60        45            67           49   \n",
      "1 2013-12-22         56        48        39            43           36   \n",
      "2 2013-12-23         58        45        32            31           27   \n",
      "3 2013-12-24         61        46        31            36           28   \n",
      "4 2013-12-25         58        50        41            44           40   \n",
      "\n",
      "  DewPointLowF HumidityHighPercent HumidityAvgPercent HumidityLowPercent  ...  \\\n",
      "0           43                  93                 75                 57  ...   \n",
      "1           28                  93                 68                 43  ...   \n",
      "2           23                  76                 52                 27  ...   \n",
      "3           21                  89                 56                 22  ...   \n",
      "4           36                  86                 71                 56  ...   \n",
      "\n",
      "  SeaLevelPressureAvgInches SeaLevelPressureLowInches VisibilityHighMiles  \\\n",
      "0                     29.68                     29.59                  10   \n",
      "1                     30.13                     29.87                  10   \n",
      "2                     30.49                     30.41                  10   \n",
      "3                     30.45                      30.3                  10   \n",
      "4                     30.33                     30.27                  10   \n",
      "\n",
      "  VisibilityAvgMiles VisibilityLowMiles WindHighMPH WindAvgMPH WindGustMPH  \\\n",
      "0                  7                  2          20          4          31   \n",
      "1                 10                  5          16          6          25   \n",
      "2                 10                 10           8          3          12   \n",
      "3                 10                  7          12          4          20   \n",
      "4                 10                  7          10          2          16   \n",
      "\n",
      "  PrecipitationSumInches               Events  \n",
      "0                   0.46  Rain , Thunderstorm  \n",
      "1                      0                       \n",
      "2                      0                       \n",
      "3                      0                       \n",
      "4                      T                       \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import getpass\n",
    "\n",
    "# Define the database connection parameters \n",
    "password = getpass.getpass('Enter your MySQL password: ')\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(f'mysql+pymysql://root:{password}@localhost/weather_data')\n",
    "\n",
    "# Now use pandas with the engine\n",
    "weather_df = pd.read_sql_query(\"SELECT * FROM austin_weather\", engine)\n",
    "\n",
    "print(weather_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Challenge 1 - Describe the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the dataset you have loaded: \n",
    "- Look at the variables and their types\n",
    "- Examine the descriptive statistics of the numeric variables \n",
    "- Look at the first five rows of all variables to evaluate the categorical variables as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1319, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1319 entries, 0 to 1318\n",
      "Data columns (total 21 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   Date                        1319 non-null   datetime64[ns]\n",
      " 1   TempHighF                   1319 non-null   int64         \n",
      " 2   TempAvgF                    1319 non-null   int64         \n",
      " 3   TempLowF                    1319 non-null   int64         \n",
      " 4   DewPointHighF               1319 non-null   object        \n",
      " 5   DewPointAvgF                1319 non-null   object        \n",
      " 6   DewPointLowF                1319 non-null   object        \n",
      " 7   HumidityHighPercent         1319 non-null   object        \n",
      " 8   HumidityAvgPercent          1319 non-null   object        \n",
      " 9   HumidityLowPercent          1319 non-null   object        \n",
      " 10  SeaLevelPressureHighInches  1319 non-null   object        \n",
      " 11  SeaLevelPressureAvgInches   1319 non-null   object        \n",
      " 12  SeaLevelPressureLowInches   1319 non-null   object        \n",
      " 13  VisibilityHighMiles         1319 non-null   object        \n",
      " 14  VisibilityAvgMiles          1319 non-null   object        \n",
      " 15  VisibilityLowMiles          1319 non-null   object        \n",
      " 16  WindHighMPH                 1319 non-null   object        \n",
      " 17  WindAvgMPH                  1319 non-null   object        \n",
      " 18  WindGustMPH                 1319 non-null   object        \n",
      " 19  PrecipitationSumInches      1319 non-null   object        \n",
      " 20  Events                      1319 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(3), object(17)\n",
      "memory usage: 216.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "weather_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "TempHighF",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TempAvgF",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TempLowF",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f71c49ee-51eb-4b36-8062-abc4a8fc9d44",
       "rows": [
        [
         "count",
         "1319",
         "1319.0",
         "1319.0",
         "1319.0"
        ],
        [
         "mean",
         "2015-10-11 00:00:00",
         "80.86277482941622",
         "70.6429112964367",
         "59.902956785443514"
        ],
        [
         "min",
         "2013-12-21 00:00:00",
         "32.0",
         "29.0",
         "19.0"
        ],
        [
         "25%",
         "2014-11-15 12:00:00",
         "72.0",
         "62.0",
         "49.0"
        ],
        [
         "50%",
         "2015-10-11 00:00:00",
         "83.0",
         "73.0",
         "63.0"
        ],
        [
         "75%",
         "2016-09-04 12:00:00",
         "92.0",
         "83.0",
         "73.0"
        ],
        [
         "max",
         "2017-07-31 00:00:00",
         "107.0",
         "93.0",
         "81.0"
        ],
        [
         "std",
         null,
         "14.766522914053354",
         "14.045903804052708",
         "14.190647994086149"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>TempHighF</th>\n",
       "      <th>TempAvgF</th>\n",
       "      <th>TempLowF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1319</td>\n",
       "      <td>1319.000000</td>\n",
       "      <td>1319.000000</td>\n",
       "      <td>1319.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2015-10-11 00:00:00</td>\n",
       "      <td>80.862775</td>\n",
       "      <td>70.642911</td>\n",
       "      <td>59.902957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2013-12-21 00:00:00</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2014-11-15 12:00:00</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2015-10-11 00:00:00</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2016-09-04 12:00:00</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2017-07-31 00:00:00</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14.766523</td>\n",
       "      <td>14.045904</td>\n",
       "      <td>14.190648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date    TempHighF     TempAvgF     TempLowF\n",
       "count                 1319  1319.000000  1319.000000  1319.000000\n",
       "mean   2015-10-11 00:00:00    80.862775    70.642911    59.902957\n",
       "min    2013-12-21 00:00:00    32.000000    29.000000    19.000000\n",
       "25%    2014-11-15 12:00:00    72.000000    62.000000    49.000000\n",
       "50%    2015-10-11 00:00:00    83.000000    73.000000    63.000000\n",
       "75%    2016-09-04 12:00:00    92.000000    83.000000    73.000000\n",
       "max    2017-07-31 00:00:00   107.000000    93.000000    81.000000\n",
       "std                    NaN    14.766523    14.045904    14.190648"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "weather_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "TempHighF",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TempAvgF",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TempLowF",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DewPointHighF",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DewPointAvgF",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DewPointLowF",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "HumidityHighPercent",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "HumidityAvgPercent",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "HumidityLowPercent",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SeaLevelPressureHighInches",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SeaLevelPressureAvgInches",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SeaLevelPressureLowInches",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "VisibilityHighMiles",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "VisibilityAvgMiles",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "VisibilityLowMiles",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "WindHighMPH",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "WindAvgMPH",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "WindGustMPH",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "PrecipitationSumInches",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Events",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "f315a94f-eed7-4e85-853b-2e8247ab74f4",
       "rows": [
        [
         "0",
         "2013-12-21 00:00:00",
         "74",
         "60",
         "45",
         "67",
         "49",
         "43",
         "93",
         "75",
         "57",
         "29.86",
         "29.68",
         "29.59",
         "10",
         "7",
         "2",
         "20",
         "4",
         "31",
         "0.46",
         "Rain , Thunderstorm"
        ],
        [
         "1",
         "2013-12-22 00:00:00",
         "56",
         "48",
         "39",
         "43",
         "36",
         "28",
         "93",
         "68",
         "43",
         "30.41",
         "30.13",
         "29.87",
         "10",
         "10",
         "5",
         "16",
         "6",
         "25",
         "0",
         " "
        ],
        [
         "2",
         "2013-12-23 00:00:00",
         "58",
         "45",
         "32",
         "31",
         "27",
         "23",
         "76",
         "52",
         "27",
         "30.56",
         "30.49",
         "30.41",
         "10",
         "10",
         "10",
         "8",
         "3",
         "12",
         "0",
         " "
        ],
        [
         "3",
         "2013-12-24 00:00:00",
         "61",
         "46",
         "31",
         "36",
         "28",
         "21",
         "89",
         "56",
         "22",
         "30.56",
         "30.45",
         "30.3",
         "10",
         "10",
         "7",
         "12",
         "4",
         "20",
         "0",
         " "
        ],
        [
         "4",
         "2013-12-25 00:00:00",
         "58",
         "50",
         "41",
         "44",
         "40",
         "36",
         "86",
         "71",
         "56",
         "30.41",
         "30.33",
         "30.27",
         "10",
         "10",
         "7",
         "10",
         "2",
         "16",
         "T",
         " "
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>TempHighF</th>\n",
       "      <th>TempAvgF</th>\n",
       "      <th>TempLowF</th>\n",
       "      <th>DewPointHighF</th>\n",
       "      <th>DewPointAvgF</th>\n",
       "      <th>DewPointLowF</th>\n",
       "      <th>HumidityHighPercent</th>\n",
       "      <th>HumidityAvgPercent</th>\n",
       "      <th>HumidityLowPercent</th>\n",
       "      <th>...</th>\n",
       "      <th>SeaLevelPressureAvgInches</th>\n",
       "      <th>SeaLevelPressureLowInches</th>\n",
       "      <th>VisibilityHighMiles</th>\n",
       "      <th>VisibilityAvgMiles</th>\n",
       "      <th>VisibilityLowMiles</th>\n",
       "      <th>WindHighMPH</th>\n",
       "      <th>WindAvgMPH</th>\n",
       "      <th>WindGustMPH</th>\n",
       "      <th>PrecipitationSumInches</th>\n",
       "      <th>Events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-21</td>\n",
       "      <td>74</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "      <td>93</td>\n",
       "      <td>75</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>29.68</td>\n",
       "      <td>29.59</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>0.46</td>\n",
       "      <td>Rain , Thunderstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-22</td>\n",
       "      <td>56</td>\n",
       "      <td>48</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>93</td>\n",
       "      <td>68</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>30.13</td>\n",
       "      <td>29.87</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-23</td>\n",
       "      <td>58</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>76</td>\n",
       "      <td>52</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>30.49</td>\n",
       "      <td>30.41</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-24</td>\n",
       "      <td>61</td>\n",
       "      <td>46</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>89</td>\n",
       "      <td>56</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>30.45</td>\n",
       "      <td>30.3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-25</td>\n",
       "      <td>58</td>\n",
       "      <td>50</td>\n",
       "      <td>41</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>86</td>\n",
       "      <td>71</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>30.33</td>\n",
       "      <td>30.27</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>T</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  TempHighF  TempAvgF  TempLowF DewPointHighF DewPointAvgF  \\\n",
       "0 2013-12-21         74        60        45            67           49   \n",
       "1 2013-12-22         56        48        39            43           36   \n",
       "2 2013-12-23         58        45        32            31           27   \n",
       "3 2013-12-24         61        46        31            36           28   \n",
       "4 2013-12-25         58        50        41            44           40   \n",
       "\n",
       "  DewPointLowF HumidityHighPercent HumidityAvgPercent HumidityLowPercent  ...  \\\n",
       "0           43                  93                 75                 57  ...   \n",
       "1           28                  93                 68                 43  ...   \n",
       "2           23                  76                 52                 27  ...   \n",
       "3           21                  89                 56                 22  ...   \n",
       "4           36                  86                 71                 56  ...   \n",
       "\n",
       "  SeaLevelPressureAvgInches SeaLevelPressureLowInches VisibilityHighMiles  \\\n",
       "0                     29.68                     29.59                  10   \n",
       "1                     30.13                     29.87                  10   \n",
       "2                     30.49                     30.41                  10   \n",
       "3                     30.45                      30.3                  10   \n",
       "4                     30.33                     30.27                  10   \n",
       "\n",
       "  VisibilityAvgMiles VisibilityLowMiles WindHighMPH WindAvgMPH WindGustMPH  \\\n",
       "0                  7                  2          20          4          31   \n",
       "1                 10                  5          16          6          25   \n",
       "2                 10                 10           8          3          12   \n",
       "3                 10                  7          12          4          20   \n",
       "4                 10                  7          10          2          16   \n",
       "\n",
       "  PrecipitationSumInches               Events  \n",
       "0                   0.46  Rain , Thunderstorm  \n",
       "1                      0                       \n",
       "2                      0                       \n",
       "3                      0                       \n",
       "4                      T                       \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "weather_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given the information you have learned from examining the dataset, write down three insights about the data in a markdown cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Insights:\n",
    "\n",
    "1. There are 21 variables in the dataset. 3 of them are numeric and the rest contain some text.\n",
    "\n",
    "2. The average temperature in Austin ranged between around 70 degrees F and around 93 degrees F. The highest temperature observed during this period was 107 degrees F and the lowest was 19 degrees F.\n",
    "\n",
    "3. When we look at the head function, we see that a lot of variables contain numeric data even though these columns are of object type. This means we might have to do some data cleansing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's examine the DewPointAvgF variable by using the `unique()` function to list all unique values in this dataframe.\n",
    "\n",
    "Describe what you find in a markdown cell below the code. What did you notice? What do you think made Pandas to treat this column as *object* instead of *int64*? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['49', '36', '27', '28', '40', '39', '41', '26', '42', '22', '48',\n",
       "       '32', '8', '11', '45', '55', '61', '37', '47', '25', '23', '20',\n",
       "       '33', '30', '29', '17', '14', '13', '54', '59', '15', '24', '34',\n",
       "       '35', '57', '50', '53', '60', '46', '56', '51', '31', '38', '62',\n",
       "       '43', '63', '64', '67', '66', '58', '70', '68', '65', '69', '71',\n",
       "       '72', '-', '73', '74', '21', '44', '52', '12', '75', '76', '18'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "weather_df['DewPointAvgF'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your observation here\n",
    "# All values are strings: Every value is enclosed in quotes ('49', '36', '27', etc.)\n",
    "# They're numeric strings: All values appear to be valid numbers, but stored as text\n",
    "# No obvious missing values: I don't see any 'N/A', '-', or empty strings\n",
    "# Data type is object: The output shows dtype=object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a list of columns misrepresented as `object`. Use this list to convert the columns to numeric using the `pandas.to_numeric` function in the next cell. If you encounter errors in converting strings to numeric values, you need to catch those errors and force the conversion by supplying `errors='coerce'` as an argument for `pandas.to_numeric`. Coercing will replace non-convertable elements with `NaN` which represents an undefined numeric value. This makes it possible for us to conveniently handle missing values in subsequent data processing.\n",
    "\n",
    "*Hint: you may use a loop to change one column at a time but it is more efficient to use `apply`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_type_columns = ['DewPointHighF', 'DewPointAvgF', 'DewPointLowF', 'HumidityHighPercent', \n",
    "                      'HumidityAvgPercent', 'HumidityLowPercent', 'SeaLevelPressureHighInches', \n",
    "                      'SeaLevelPressureAvgInches' ,'SeaLevelPressureLowInches', 'VisibilityHighMiles',\n",
    "                      'VisibilityAvgMiles', 'VisibilityLowMiles', 'WindHighMPH', 'WindAvgMPH', \n",
    "                      'WindGustMPH', 'PrecipitationSumInches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Apply pd.to_numeric to all columns at once\n",
    "weather_df[wrong_type_columns] = weather_df[wrong_type_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if your code has worked by printing the data types again. You should see only two `object` columns (`Date` and `Events`) now. All other columns should be `int64` or `float64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types after conversion:\n",
      "DewPointHighF                 float64\n",
      "DewPointAvgF                  float64\n",
      "DewPointLowF                  float64\n",
      "HumidityHighPercent           float64\n",
      "HumidityAvgPercent            float64\n",
      "HumidityLowPercent            float64\n",
      "SeaLevelPressureHighInches    float64\n",
      "SeaLevelPressureAvgInches     float64\n",
      "SeaLevelPressureLowInches     float64\n",
      "VisibilityHighMiles           float64\n",
      "VisibilityAvgMiles            float64\n",
      "VisibilityLowMiles            float64\n",
      "WindHighMPH                   float64\n",
      "WindAvgMPH                    float64\n",
      "WindGustMPH                   float64\n",
      "PrecipitationSumInches        float64\n",
      "dtype: object\n",
      "\n",
      "NaN counts per column:\n",
      "DewPointHighF                   7\n",
      "DewPointAvgF                    7\n",
      "DewPointLowF                    7\n",
      "HumidityHighPercent             2\n",
      "HumidityAvgPercent              2\n",
      "HumidityLowPercent              2\n",
      "SeaLevelPressureHighInches      3\n",
      "SeaLevelPressureAvgInches       3\n",
      "SeaLevelPressureLowInches       3\n",
      "VisibilityHighMiles            12\n",
      "VisibilityAvgMiles             12\n",
      "VisibilityLowMiles             12\n",
      "WindHighMPH                     2\n",
      "WindAvgMPH                      2\n",
      "WindGustMPH                     4\n",
      "PrecipitationSumInches        124\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Check data types after conversion\n",
    "print(\"Data types after conversion:\")\n",
    "print(weather_df[wrong_type_columns].dtypes)\n",
    "\n",
    "# Check for any NaN values that resulted from coercion\n",
    "print(\"\\nNaN counts per column:\")\n",
    "print(weather_df[wrong_type_columns].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Handle the Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have fixed the type mismatch, let's address the missing data.\n",
    "\n",
    "By coercing the columns to numeric, we have created `NaN` for each cell containing characters. We should choose a strategy to address these missing data.\n",
    "\n",
    "The first step is to examine how many rows contain missing data.\n",
    "\n",
    "We check how much missing data we have by applying the `.isnull()` function to our dataset. To find the rows with missing data in any of its cells, we apply `.any(axis=1)` to the function. `austin.isnull().any(axis=1)` will return a column containing true if the row contains at least one missing value and false otherwise. Therefore we must subset our dataframe with this column. This will give us all rows with at least one missing value. \n",
    "\n",
    "#### In the next cell, identify all rows containing at least one missing value. Assign the dataframes with missing values to a variable called `missing_values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DewPointHighF",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "DewPointAvgF",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "DewPointLowF",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "HumidityHighPercent",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "HumidityAvgPercent",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "HumidityLowPercent",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "SeaLevelPressureHighInches",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "SeaLevelPressureAvgInches",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "SeaLevelPressureLowInches",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "VisibilityHighMiles",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "VisibilityAvgMiles",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "VisibilityLowMiles",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "WindHighMPH",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "WindAvgMPH",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "WindGustMPH",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "PrecipitationSumInches",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "dda7b389-9b8e-4883-8b77-603705536833",
       "rows": [
        [
         "0",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "1",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "2",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "3",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "4",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "5",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "6",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "7",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "8",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "9",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "10",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "11",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "12",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "13",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "14",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "15",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "16",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "17",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "18",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "19",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "20",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "21",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "22",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "23",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "24",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "25",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "26",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "27",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "28",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "29",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "30",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "31",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "32",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "33",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "34",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "35",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "36",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "37",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "38",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "39",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "40",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "41",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "42",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "True"
        ],
        [
         "43",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "44",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "45",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "46",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "47",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "48",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "49",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False",
         "False"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 1319
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DewPointHighF</th>\n",
       "      <th>DewPointAvgF</th>\n",
       "      <th>DewPointLowF</th>\n",
       "      <th>HumidityHighPercent</th>\n",
       "      <th>HumidityAvgPercent</th>\n",
       "      <th>HumidityLowPercent</th>\n",
       "      <th>SeaLevelPressureHighInches</th>\n",
       "      <th>SeaLevelPressureAvgInches</th>\n",
       "      <th>SeaLevelPressureLowInches</th>\n",
       "      <th>VisibilityHighMiles</th>\n",
       "      <th>VisibilityAvgMiles</th>\n",
       "      <th>VisibilityLowMiles</th>\n",
       "      <th>WindHighMPH</th>\n",
       "      <th>WindAvgMPH</th>\n",
       "      <th>WindGustMPH</th>\n",
       "      <th>PrecipitationSumInches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1319 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DewPointHighF  DewPointAvgF  DewPointLowF  HumidityHighPercent  \\\n",
       "0             False         False         False                False   \n",
       "1             False         False         False                False   \n",
       "2             False         False         False                False   \n",
       "3             False         False         False                False   \n",
       "4             False         False         False                False   \n",
       "...             ...           ...           ...                  ...   \n",
       "1314          False         False         False                False   \n",
       "1315          False         False         False                False   \n",
       "1316          False         False         False                False   \n",
       "1317          False         False         False                False   \n",
       "1318          False         False         False                False   \n",
       "\n",
       "      HumidityAvgPercent  HumidityLowPercent  SeaLevelPressureHighInches  \\\n",
       "0                  False               False                       False   \n",
       "1                  False               False                       False   \n",
       "2                  False               False                       False   \n",
       "3                  False               False                       False   \n",
       "4                  False               False                       False   \n",
       "...                  ...                 ...                         ...   \n",
       "1314               False               False                       False   \n",
       "1315               False               False                       False   \n",
       "1316               False               False                       False   \n",
       "1317               False               False                       False   \n",
       "1318               False               False                       False   \n",
       "\n",
       "      SeaLevelPressureAvgInches  SeaLevelPressureLowInches  \\\n",
       "0                         False                      False   \n",
       "1                         False                      False   \n",
       "2                         False                      False   \n",
       "3                         False                      False   \n",
       "4                         False                      False   \n",
       "...                         ...                        ...   \n",
       "1314                      False                      False   \n",
       "1315                      False                      False   \n",
       "1316                      False                      False   \n",
       "1317                      False                      False   \n",
       "1318                      False                      False   \n",
       "\n",
       "      VisibilityHighMiles  VisibilityAvgMiles  VisibilityLowMiles  \\\n",
       "0                   False               False               False   \n",
       "1                   False               False               False   \n",
       "2                   False               False               False   \n",
       "3                   False               False               False   \n",
       "4                   False               False               False   \n",
       "...                   ...                 ...                 ...   \n",
       "1314                False               False               False   \n",
       "1315                False               False               False   \n",
       "1316                False               False               False   \n",
       "1317                False               False               False   \n",
       "1318                False               False               False   \n",
       "\n",
       "      WindHighMPH  WindAvgMPH  WindGustMPH  PrecipitationSumInches  \n",
       "0           False       False        False                   False  \n",
       "1           False       False        False                   False  \n",
       "2           False       False        False                   False  \n",
       "3           False       False        False                   False  \n",
       "4           False       False        False                    True  \n",
       "...           ...         ...          ...                     ...  \n",
       "1314        False       False        False                   False  \n",
       "1315        False       False        False                   False  \n",
       "1316        False       False        False                   False  \n",
       "1317        False       False        False                   False  \n",
       "1318        False       False        False                   False  \n",
       "\n",
       "[1319 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "weather_df[wrong_type_columns].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all rows containing at least one missing value\n",
    "missing_values = weather_df[weather_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in weather_df: 1319\n",
      "Rows with missing values: 136\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows\n",
    "print(f\"Total rows in weather_df: {len(weather_df)}\")\n",
    "print(f\"Rows with missing values: {len(missing_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "DewPointHighF                   7\n",
      "DewPointAvgF                    7\n",
      "DewPointLowF                    7\n",
      "HumidityHighPercent             2\n",
      "HumidityAvgPercent              2\n",
      "HumidityLowPercent              2\n",
      "SeaLevelPressureHighInches      3\n",
      "SeaLevelPressureAvgInches       3\n",
      "SeaLevelPressureLowInches       3\n",
      "VisibilityHighMiles            12\n",
      "VisibilityAvgMiles             12\n",
      "VisibilityLowMiles             12\n",
      "WindHighMPH                     2\n",
      "WindAvgMPH                      2\n",
      "WindGustMPH                     4\n",
      "PrecipitationSumInches        124\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find the number of missing rows in each column\n",
    "missing_per_column = weather_df.isna().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_per_column[missing_per_column > 0])  # Only show columns with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple strategies to handle missing data. Below lists the most common ones data scientists use:\n",
    "\n",
    "* Removing all rows or all columns containing missing data. This is the simplest strategy. It may work in some cases but not others.\n",
    "\n",
    "* Filling all missing values with a placeholder value. \n",
    "    * For categorical data, `0`, `-1`, and `9999` are some commonly used placeholder values. \n",
    "    * For continuous data, some may opt to fill all missing data with the mean. This strategy is not optimal since it can increase the fit of the model.\n",
    "\n",
    "* Filling the values using some algorithm. \n",
    "\n",
    "#### In our case, we will use a hybrid approach which is to first remove the data that contain most missing values then fill in the rest of the missing values with the *linear interpolation* algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, count the number of rows of `austin` and `missing_values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in weather_df: 1319\n",
      "Rows with missing values: 136\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Count the number of rows\n",
    "print(f\"Total rows in weather_df: {len(weather_df)}\")\n",
    "print(f\"Rows with missing values: {len(missing_values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the ratio of missing rows to total rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of missing rows to total rows: 0.1031 (10.31%)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Calculate the ratio of missing rows to total rows\n",
    "missing_ratio = len(missing_values) / len(weather_df)\n",
    "print(f\"Ratio of missing rows to total rows: {missing_ratio:.4f} ({missing_ratio*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is a large proportion of missing data (over 10%). Perhaps we should evaluate which columns have the most missing data and remove those columns. For the remaining columns, we will perform a linear approximation of the missing data.\n",
    "\n",
    "We can find the number of missing rows in each column using the `.isna()` function. We then chain the `.sum` function to the `.isna()` function and find the number of missing rows per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "DewPointHighF                   7\n",
      "DewPointAvgF                    7\n",
      "DewPointLowF                    7\n",
      "HumidityHighPercent             2\n",
      "HumidityAvgPercent              2\n",
      "HumidityLowPercent              2\n",
      "SeaLevelPressureHighInches      3\n",
      "SeaLevelPressureAvgInches       3\n",
      "SeaLevelPressureLowInches       3\n",
      "VisibilityHighMiles            12\n",
      "VisibilityAvgMiles             12\n",
      "VisibilityLowMiles             12\n",
      "WindHighMPH                     2\n",
      "WindAvgMPH                      2\n",
      "WindGustMPH                     4\n",
      "PrecipitationSumInches        124\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Find the number of missing rows in each column\n",
    "missing_per_column = weather_df.isna().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_per_column[missing_per_column > 0])  # Only show columns with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see from the output, the majority of missing data is in one column called `PrecipitationSumInches`. What's the number of missing values in this column in ratio to its total number of rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in PrecipitationSumInches: 124\n",
      "Missing ratio: 0.0940 (9.40%)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Calculate missing ratio for PrecipitationSumInches\n",
    "precip_missing = weather_df['PrecipitationSumInches'].isna().sum()\n",
    "precip_total = len(weather_df)\n",
    "precip_ratio = precip_missing / precip_total\n",
    "\n",
    "print(f\"Missing values in PrecipitationSumInches: {precip_missing}\")\n",
    "print(f\"Missing ratio: {precip_ratio:.4f} ({precip_ratio*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost 10% data missing! Therefore, we prefer to remove this column instead of filling its missing values. \n",
    "\n",
    "#### Remove this column from `austin` using the `.drop()` function. Use the `inplace=True` argument.\n",
    "\n",
    "*Hints:*\n",
    "\n",
    "* By supplying `inplace=True` to `drop()`, the original dataframe object will be changed in place and the function will return `None`. In contrast, if you don't supply `inplace=True`, which is equivalent to supplying `inplace=False` because `False` is the default value, the original dataframe object will be kept and the function returns a copy of the transformed dataframe object. In the latter case, you'll have to assign the returned object back to your variable.\n",
    "\n",
    "* Also, since you are dropping a column instead of a row, you'll need to supply `axis=1` to `drop()`.\n",
    "\n",
    "[Reference for `pandas.DataFrame.drop`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after dropping PrecipitationSumInches:\n",
      "['Date', 'TempHighF', 'TempAvgF', 'TempLowF', 'DewPointHighF', 'DewPointAvgF', 'DewPointLowF', 'HumidityHighPercent', 'HumidityAvgPercent', 'HumidityLowPercent', 'SeaLevelPressureHighInches', 'SeaLevelPressureAvgInches', 'SeaLevelPressureLowInches', 'VisibilityHighMiles', 'VisibilityAvgMiles', 'VisibilityLowMiles', 'WindHighMPH', 'WindAvgMPH', 'WindGustMPH', 'Events']\n",
      "Shape: (1319, 20)\n"
     ]
    }
   ],
   "source": [
    "# Your code here \n",
    "# Remove PrecipitationSumInches column\n",
    "weather_df.drop('PrecipitationSumInches', axis=1, inplace=True)\n",
    "\n",
    "# Print `austin` to confirm the column is indeed removed\n",
    "print(\"Columns after dropping PrecipitationSumInches:\")\n",
    "print(weather_df.columns.tolist())\n",
    "print(f\"Shape: {weather_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we will perform linear interpolation of the missing data.\n",
    "\n",
    "This means that we will use a linear algorithm to estimate the missing data. Linear interpolation assumes that there is a straight line between the points and the missing point will fall on that line. This is a good enough approximation for weather related data. Weather related data is typically a time series. Therefore, we do not want to drop rows from our data if possible. It is prefereable to estimate the missing values rather than remove the rows. However, if you have data from a single point in time, perhaps a better solution would be to remove the rows. \n",
    "\n",
    "If you would like to read more about linear interpolation, you can do so [here](https://en.wikipedia.org/wiki/Linear_interpolation).\n",
    "\n",
    "In the following cell, use the `.interpolate()` function on the entire dataframe. This time pass the `inplace=False` argument to the function and assign the interpolated dataframe to a new variable called `austin_fixed` so that we can compare with `austin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edumc\\AppData\\Local\\Temp\\ipykernel_55896\\211276965.py:3: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  austin_fixed = weather_df.interpolate(inplace=False)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Perform linear interpolation on the remaining missing data\n",
    "austin_fixed = weather_df.interpolate(inplace=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check to make sure `austin_fixed` contains no missing data. Also check `austin` - it still contains missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in austin_fixed:\n",
      "0\n",
      "Missing values in original weather_df: 80\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "print(\"Missing values in austin_fixed:\")\n",
    "print(austin_fixed.isnull().sum().sum())  # Should be 0\n",
    "\n",
    "# Also check austin still contains missing data\n",
    "print(f\"Missing values in original weather_df: {weather_df.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Processing the `Events` Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our dataframe contains one true text column - the Events column. We should evaluate this column to determine how to process it.\n",
    "\n",
    "Use the `value_counts()` function to evaluate the contents of this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events column value counts:\n",
      "Events\n",
      "                             903\n",
      "Rain                         192\n",
      "Rain , Thunderstorm          137\n",
      "Fog , Rain , Thunderstorm     33\n",
      "Fog                           21\n",
      "Thunderstorm                  17\n",
      "Fog , Rain                    14\n",
      "Rain , Snow                    1\n",
      "Fog , Thunderstorm             1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "print(\"Events column value counts:\")\n",
    "print(austin_fixed['Events'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rain , Thunderstorm' ' ' 'Rain' 'Fog' 'Rain , Snow' 'Fog , Rain'\n",
      " 'Thunderstorm' 'Fog , Rain , Thunderstorm' 'Fog , Thunderstorm']\n"
     ]
    }
   ],
   "source": [
    "print(austin_fixed['Events'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the values of `Events` and reflecting what those values mean in the context of data, you realize this column indicates what weather events had happened in a particular day.\n",
    "\n",
    "#### What is the largest number of events happened in a single day? Enter your answer in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of events in a single day: 3\n",
      "\n",
      "Days with 3 events:\n",
      "           Date                     Events\n",
      "114  2014-04-14  Fog , Rain , Thunderstorm\n",
      "142  2014-05-12  Fog , Rain , Thunderstorm\n",
      "157  2014-05-27  Fog , Rain , Thunderstorm\n",
      "185  2014-06-24  Fog , Rain , Thunderstorm\n",
      "186  2014-06-25  Fog , Rain , Thunderstorm\n",
      "208  2014-07-17  Fog , Rain , Thunderstorm\n",
      "257  2014-09-04  Fog , Rain , Thunderstorm\n",
      "271  2014-09-18  Fog , Rain , Thunderstorm\n",
      "336  2014-11-22  Fog , Rain , Thunderstorm\n",
      "438  2015-03-04  Fog , Rain , Thunderstorm\n",
      "483  2015-04-18  Fog , Rain , Thunderstorm\n",
      "500  2015-05-05  Fog , Rain , Thunderstorm\n",
      "508  2015-05-13  Fog , Rain , Thunderstorm\n",
      "518  2015-05-23  Fog , Rain , Thunderstorm\n",
      "520  2015-05-25  Fog , Rain , Thunderstorm\n",
      "540  2015-06-14  Fog , Rain , Thunderstorm\n",
      "542  2015-06-16  Fog , Rain , Thunderstorm\n",
      "543  2015-06-17  Fog , Rain , Thunderstorm\n",
      "545  2015-06-19  Fog , Rain , Thunderstorm\n",
      "546  2015-06-20  Fog , Rain , Thunderstorm\n",
      "547  2015-06-21  Fog , Rain , Thunderstorm\n",
      "556  2015-06-30  Fog , Rain , Thunderstorm\n",
      "628  2015-09-10  Fog , Rain , Thunderstorm\n",
      "678  2015-10-30  Fog , Rain , Thunderstorm\n",
      "848  2016-04-17  Fog , Rain , Thunderstorm\n",
      "861  2016-04-30  Fog , Rain , Thunderstorm\n",
      "889  2016-05-28  Fog , Rain , Thunderstorm\n",
      "949  2016-07-27  Fog , Rain , Thunderstorm\n",
      "969  2016-08-16  Fog , Rain , Thunderstorm\n",
      "1009 2016-09-25  Fog , Rain , Thunderstorm\n",
      "1048 2016-11-03  Fog , Rain , Thunderstorm\n",
      "1123 2017-01-17  Fog , Rain , Thunderstorm\n",
      "1262 2017-06-05  Fog , Rain , Thunderstorm\n"
     ]
    }
   ],
   "source": [
    "# Your answer:\n",
    "# Look at the events to find the maximum number of events in a single day\n",
    "# We need to count how many events are in each row by splitting on commas\n",
    "event_counts = austin_fixed['Events'].apply(lambda x: len([event.strip() for event in str(x).split(',') if event.strip() and event.strip() != '']) if x and str(x).strip() else 0)\n",
    "\n",
    "print(f\"Maximum number of events in a single day: {event_counts.max()}\")\n",
    "\n",
    "# Let's also see which days had the most events\n",
    "max_events_mask = event_counts == event_counts.max()\n",
    "print(f\"\\nDays with {event_counts.max()} events:\")\n",
    "print(austin_fixed[max_events_mask][['Date', 'Events']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want to transform the string-type `Events` values to the numbers. This will allow us to apply machine learning algorithms easily.\n",
    "\n",
    "How? We will create a new column for each type of events (i.e. *Rain*, *Snow*, *Fog*, *Thunderstorm*. In each column, we use `1` to indicate if the corresponding event happened in that day and use `0` otherwise.\n",
    "\n",
    "Below we provide you a list of all event types. Loop the list and create a dummy column with `0` values for each event in `austin_fixed`. To create a new dummy column with `0` values, simply use `austin_fixed[event] = 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New columns added:\n",
      "        Date               Events  Snow  Fog  Rain  Thunderstorm\n",
      "0 2013-12-21  Rain , Thunderstorm     0    0     0             0\n",
      "1 2013-12-22                          0    0     0             0\n",
      "2 2013-12-23                          0    0     0             0\n",
      "3 2013-12-24                          0    0     0             0\n",
      "4 2013-12-25                          0    0     0             0\n",
      "\n",
      "Dataframe shape: (1319, 24)\n"
     ]
    }
   ],
   "source": [
    "event_list = ['Snow', 'Fog', 'Rain', 'Thunderstorm']\n",
    "\n",
    "# Your code here\n",
    "# Create dummy columns with 0 values for each event\n",
    "for event in event_list:\n",
    "    austin_fixed[event] = 0\n",
    "\n",
    "# Print your new dataframe to check whether new columns have been created:\n",
    "print(\"New columns added:\")\n",
    "print(austin_fixed[['Date', 'Events'] + event_list].head())\n",
    "print(f\"\\nDataframe shape: {austin_fixed.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, populate the actual values in the dummy columns of  `austin_fixed`.\n",
    "\n",
    "You will check the *Events* column. If its string value contains `Rain`, then the *Rain* column should be `1`. The same for `Snow`, `Fog`, and `Thunderstorm`.\n",
    "\n",
    "*Hints:*\n",
    "\n",
    "* Use [`pandas.Series.str.contains()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.contains.html) to create the value series of each new column.\n",
    "\n",
    "* What if the values you populated are booleans instead of numbers? You can cast the boolean values to numbers by using `.astype(int)`. For instance, `pd.Series([True, True, False]).astype(int)` will return a new series with values of `[1, 1, 0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "for event in event_list:\n",
    "    # Use pandas.Series.str.contains() to create the value series\n",
    "    contains_event = austin_fixed['Events'].str.contains(event, na=False)\n",
    "    # Convert boolean series to integer (True becomes 1, False becomes 0)\n",
    "    austin_fixed[event] = contains_event.astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out `austin_fixed` to check if the event columns are populated with the intended values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of populated event columns:\n",
      "           Date               Events  Snow  Fog  Rain  Thunderstorm\n",
      "307  2014-10-24                          0    0     0             0\n",
      "361  2014-12-17  Rain , Thunderstorm     0    0     1             1\n",
      "96   2014-03-27                 Rain     0    0     1             0\n",
      "285  2014-10-02  Rain , Thunderstorm     0    0     1             1\n",
      "1191 2017-03-26                          0    0     0             0\n",
      "1189 2017-03-24                 Rain     0    0     1             0\n",
      "195  2014-07-04         Thunderstorm     0    0     0             1\n",
      "838  2016-04-07                          0    0     0             0\n",
      "1061 2016-11-16                          0    0     0             0\n",
      "190  2014-06-29                          0    0     0             0\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "print(\"Sample of populated event columns:\")\n",
    "print(austin_fixed[['Date', 'Events']+ event_list].sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If your code worked correctly, now we can drop the `Events` column as we don't need it any more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "austin_fixed.drop('Events', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after dropping Events:\n",
      "['Date', 'TempHighF', 'TempAvgF', 'TempLowF', 'DewPointHighF', 'DewPointAvgF', 'DewPointLowF', 'HumidityHighPercent', 'HumidityAvgPercent', 'HumidityLowPercent', 'SeaLevelPressureHighInches', 'SeaLevelPressureAvgInches', 'SeaLevelPressureLowInches', 'VisibilityHighMiles', 'VisibilityAvgMiles', 'VisibilityLowMiles', 'WindHighMPH', 'WindAvgMPH', 'WindGustMPH', 'Snow', 'Fog', 'Rain', 'Thunderstorm']\n",
      "Shape: (1319, 23)\n",
      "\n",
      "Sample of final data with event columns:\n",
      "        Date  Snow  Fog  Rain  Thunderstorm\n",
      "0 2013-12-21     0    0     1             1\n",
      "1 2013-12-22     0    0     0             0\n",
      "2 2013-12-23     0    0     0             0\n",
      "3 2013-12-24     0    0     0             0\n",
      "4 2013-12-25     0    0     0             0\n"
     ]
    }
   ],
   "source": [
    "# Print the dataframe to confirm Events column is removed\n",
    "print(\"Columns after dropping Events:\")\n",
    "print(austin_fixed.columns.tolist())\n",
    "print(f\"Shape: {austin_fixed.shape}\")\n",
    "\n",
    "# Show a sample of the final data\n",
    "print(\"\\nSample of final data with event columns:\")\n",
    "print(austin_fixed[['Date'] + event_list].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final event summary:\n",
      "Total event occurrences across all days: 635\n"
     ]
    }
   ],
   "source": [
    "# Final verification - let's make sure our encoding makes sense\n",
    "print(\"Final event summary:\")\n",
    "total_event_days = austin_fixed[event_list].sum(axis=1).sum()\n",
    "print(f\"Total event occurrences across all days: {total_event_days}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days with multiple events: 186\n",
      "Sample days with multiple events:\n",
      "         Date  Snow  Fog  Rain  Thunderstorm\n",
      "0  2013-12-21     0    0     1             1\n",
      "33 2014-01-23     1    0     1             0\n",
      "72 2014-03-03     0    0     1             1\n",
      "77 2014-03-08     0    0     1             1\n",
      "84 2014-03-15     0    1     1             0\n"
     ]
    }
   ],
   "source": [
    "# Check for days with multiple events\n",
    "multiple_events = austin_fixed[austin_fixed[event_list].sum(axis=1) > 1]\n",
    "print(f\"Days with multiple events: {len(multiple_events)}\")\n",
    "\n",
    "if len(multiple_events) > 0:\n",
    "    print(\"Sample days with multiple events:\")\n",
    "    print(multiple_events[['Date'] + event_list].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Processing The `Date` Column\n",
    "\n",
    "The `Date` column is another non-numeric field in our dataset. A value in that field looks like `'2014-01-06'` which consists of the year, month, and day connected with hyphens. One way to convert the date string to numerical is using a similar approach as we used for `Events`, namely splitting the column into numerical `Year`, `Month`, and `Day` columns. In this challenge we'll show you another way which is to use the Python `datetime` library's `toordinal()` function. Depending on what actual machine learning analysis you will conduct, each approach has its pros and cons. Our goal today is to practice data preparation so we'll skip the discussion here.\n",
    "\n",
    "Here you can find the [reference](https://docs.python.org/3/library/datetime.html) and [example](https://stackoverflow.com/questions/39846918/convert-date-to-ordinal-python) for `toordinal`. The basic process is to first convert the string to a `datetime` object using `datetime.datetime.strptime`, then convert the `datetime` object to numerical using `toordinal`.\n",
    "\n",
    "#### In the cell below, convert the `Date` column values from string to numeric values using `toordinal()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Date column info:\n",
      "Data type: datetime64[ns]\n",
      "Sample values:\n",
      "0   2013-12-21\n",
      "1   2013-12-22\n",
      "2   2013-12-23\n",
      "3   2013-12-24\n",
      "4   2013-12-25\n",
      "Name: Date, dtype: datetime64[ns]\n",
      "Date range: 2013-12-21 00:00:00 to 2017-07-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "import datetime\n",
    "\n",
    "# First, let's examine the current Date column\n",
    "print(\"Current Date column info:\")\n",
    "print(f\"Data type: {austin_fixed['Date'].dtype}\")\n",
    "print(\"Sample values:\")\n",
    "print(austin_fixed['Date'].head())\n",
    "print(f\"Date range: {austin_fixed['Date'].min()} to {austin_fixed['Date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date is already datetime type, converting directly to ordinal...\n"
     ]
    }
   ],
   "source": [
    "if austin_fixed['Date'].dtype == 'datetime64[ns]':\n",
    "    print(\"Date is already datetime type, converting directly to ordinal...\")\n",
    "    austin_fixed['Date'] = austin_fixed['Date'].dt.date.apply(lambda x: x.toordinal())\n",
    "else:\n",
    "    # Method 2: If Date is string type, convert via strptime first\n",
    "    print(\"Converting string dates to ordinal...\")\n",
    "    austin_fixed['Date'] = austin_fixed['Date'].apply(\n",
    "        lambda x: datetime.datetime.strptime(str(x), '%Y-%m-%d').toordinal()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print `austin_fixed` to check your `Date` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TempHighF",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TempAvgF",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TempLowF",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DewPointHighF",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DewPointAvgF",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DewPointLowF",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HumidityHighPercent",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HumidityAvgPercent",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HumidityLowPercent",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SeaLevelPressureHighInches",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SeaLevelPressureAvgInches",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SeaLevelPressureLowInches",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VisibilityHighMiles",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VisibilityAvgMiles",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VisibilityLowMiles",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WindHighMPH",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WindAvgMPH",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "WindGustMPH",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Snow",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Fog",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Rain",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Thunderstorm",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "a9522d94-f58e-47b7-942f-47d57925624b",
       "rows": [
        [
         "0",
         "735223",
         "74",
         "60",
         "45",
         "67.0",
         "49.0",
         "43.0",
         "93.0",
         "75.0",
         "57.0",
         "29.86",
         "29.68",
         "29.59",
         "10.0",
         "7.0",
         "2.0",
         "20.0",
         "4.0",
         "31.0",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "1",
         "735224",
         "56",
         "48",
         "39",
         "43.0",
         "36.0",
         "28.0",
         "93.0",
         "68.0",
         "43.0",
         "30.41",
         "30.13",
         "29.87",
         "10.0",
         "10.0",
         "5.0",
         "16.0",
         "6.0",
         "25.0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2",
         "735225",
         "58",
         "45",
         "32",
         "31.0",
         "27.0",
         "23.0",
         "76.0",
         "52.0",
         "27.0",
         "30.56",
         "30.49",
         "30.41",
         "10.0",
         "10.0",
         "10.0",
         "8.0",
         "3.0",
         "12.0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3",
         "735226",
         "61",
         "46",
         "31",
         "36.0",
         "28.0",
         "21.0",
         "89.0",
         "56.0",
         "22.0",
         "30.56",
         "30.45",
         "30.3",
         "10.0",
         "10.0",
         "7.0",
         "12.0",
         "4.0",
         "20.0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "4",
         "735227",
         "58",
         "50",
         "41",
         "44.0",
         "40.0",
         "36.0",
         "86.0",
         "71.0",
         "56.0",
         "30.41",
         "30.33",
         "30.27",
         "10.0",
         "10.0",
         "7.0",
         "10.0",
         "2.0",
         "16.0",
         "0",
         "0",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 23,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>TempHighF</th>\n",
       "      <th>TempAvgF</th>\n",
       "      <th>TempLowF</th>\n",
       "      <th>DewPointHighF</th>\n",
       "      <th>DewPointAvgF</th>\n",
       "      <th>DewPointLowF</th>\n",
       "      <th>HumidityHighPercent</th>\n",
       "      <th>HumidityAvgPercent</th>\n",
       "      <th>HumidityLowPercent</th>\n",
       "      <th>...</th>\n",
       "      <th>VisibilityHighMiles</th>\n",
       "      <th>VisibilityAvgMiles</th>\n",
       "      <th>VisibilityLowMiles</th>\n",
       "      <th>WindHighMPH</th>\n",
       "      <th>WindAvgMPH</th>\n",
       "      <th>WindGustMPH</th>\n",
       "      <th>Snow</th>\n",
       "      <th>Fog</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Thunderstorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>735223</td>\n",
       "      <td>74</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>67.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>735224</td>\n",
       "      <td>56</td>\n",
       "      <td>48</td>\n",
       "      <td>39</td>\n",
       "      <td>43.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>735225</td>\n",
       "      <td>58</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>31.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>735226</td>\n",
       "      <td>61</td>\n",
       "      <td>46</td>\n",
       "      <td>31</td>\n",
       "      <td>36.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>735227</td>\n",
       "      <td>58</td>\n",
       "      <td>50</td>\n",
       "      <td>41</td>\n",
       "      <td>44.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date  TempHighF  TempAvgF  TempLowF  DewPointHighF  DewPointAvgF  \\\n",
       "0  735223         74        60        45           67.0          49.0   \n",
       "1  735224         56        48        39           43.0          36.0   \n",
       "2  735225         58        45        32           31.0          27.0   \n",
       "3  735226         61        46        31           36.0          28.0   \n",
       "4  735227         58        50        41           44.0          40.0   \n",
       "\n",
       "   DewPointLowF  HumidityHighPercent  HumidityAvgPercent  HumidityLowPercent  \\\n",
       "0          43.0                 93.0                75.0                57.0   \n",
       "1          28.0                 93.0                68.0                43.0   \n",
       "2          23.0                 76.0                52.0                27.0   \n",
       "3          21.0                 89.0                56.0                22.0   \n",
       "4          36.0                 86.0                71.0                56.0   \n",
       "\n",
       "   ...  VisibilityHighMiles  VisibilityAvgMiles  VisibilityLowMiles  \\\n",
       "0  ...                 10.0                 7.0                 2.0   \n",
       "1  ...                 10.0                10.0                 5.0   \n",
       "2  ...                 10.0                10.0                10.0   \n",
       "3  ...                 10.0                10.0                 7.0   \n",
       "4  ...                 10.0                10.0                 7.0   \n",
       "\n",
       "   WindHighMPH  WindAvgMPH  WindGustMPH  Snow  Fog  Rain  Thunderstorm  \n",
       "0         20.0         4.0         31.0     0    0     1             1  \n",
       "1         16.0         6.0         25.0     0    0     0             0  \n",
       "2          8.0         3.0         12.0     0    0     0             0  \n",
       "3         12.0         4.0         20.0     0    0     0             0  \n",
       "4         10.0         2.0         16.0     0    0     0             0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austin_fixed.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 5 - Sampling and Holdout Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have processed the data for machine learning, we will separate the data to test and training sets.\n",
    "\n",
    "We first train the model using only the training set. We check our metrics on the training set. We then apply the model to the test set and check our metrics on the test set as well. If the metrics are significantly more optimal on the training set, then we know we have overfit our model. We will need to revise our model to ensure it will be more applicable to data outside the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the next cells we will separate the data into a training set and a test set using the `train_test_split()` function in scikit-learn.\n",
    "\n",
    "When using `scikit-learn` for machine learning, we first separate the data to predictor and response variables. This is the standard way of passing datasets into a model in `scikit-learn`. The `scikit-learn` will then find out whether the predictors and responses fit the model.\n",
    "\n",
    "In the next cell, assign the `TempAvgF` column to `y` and the remaining columns to `X`. Your `X` should be a subset of `austin_fixed` containing the following columns: \n",
    "\n",
    "```['Date',\n",
    " 'TempHighF',\n",
    " 'TempLowF',\n",
    " 'DewPointHighF',\n",
    " 'DewPointAvgF',\n",
    " 'DewPointLowF',\n",
    " 'HumidityHighPercent',\n",
    " 'HumidityAvgPercent',\n",
    " 'HumidityLowPercent',\n",
    " 'SeaLevelPressureHighInches',\n",
    " 'SeaLevelPressureAvgInches',\n",
    " 'SeaLevelPressureLowInches',\n",
    " 'VisibilityHighMiles',\n",
    " 'VisibilityAvgMiles',\n",
    " 'VisibilityLowMiles',\n",
    " 'WindHighMPH',\n",
    " 'WindAvgMPH',\n",
    " 'WindGustMPH',\n",
    " 'Snow',\n",
    " 'Fog',\n",
    " 'Rain',\n",
    " 'Thunderstorm']```\n",
    " \n",
    " Your `y` should be a subset of `austin_fixed` containing one column `TempAvgF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable (y):\n",
      "Shape: (1319,)\n",
      "Variable: TempAvgF\n",
      "Sample values:\n",
      "0    60\n",
      "1    48\n",
      "2    45\n",
      "3    46\n",
      "4    50\n",
      "Name: TempAvgF, dtype: int64\n",
      "\n",
      "Predictor variables (X):\n",
      "Shape: (1319, 22)\n",
      "Columns:\n",
      "['Date', 'TempHighF', 'TempLowF', 'DewPointHighF', 'DewPointAvgF', 'DewPointLowF', 'HumidityHighPercent', 'HumidityAvgPercent', 'HumidityLowPercent', 'SeaLevelPressureHighInches', 'SeaLevelPressureAvgInches', 'SeaLevelPressureLowInches', 'VisibilityHighMiles', 'VisibilityAvgMiles', 'VisibilityLowMiles', 'WindHighMPH', 'WindAvgMPH', 'WindGustMPH', 'Snow', 'Fog', 'Rain', 'Thunderstorm']\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "# Assign the TempAvgF column to y (target variable)\n",
    "y = austin_fixed['TempAvgF']\n",
    "\n",
    "# Assign the remaining columns to X (predictor variables)\n",
    "# All columns except TempAvgF\n",
    "X = austin_fixed.drop('TempAvgF', axis=1)\n",
    "\n",
    "print(\"Target variable (y):\")\n",
    "print(f\"Shape: {y.shape}\")\n",
    "print(f\"Variable: TempAvgF\")\n",
    "print(\"Sample values:\")\n",
    "print(y.head())\n",
    "\n",
    "print(f\"\\nPredictor variables (X):\")\n",
    "print(f\"Shape: {X.shape}\")\n",
    "print(\"Columns:\")\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected columns vs Actual columns:\n",
      "Expected: 22 columns\n",
      "Actual: 22 columns\n",
      "✓ All columns match perfectly!\n"
     ]
    }
   ],
   "source": [
    "# Let's verify X contains the expected columns from the challenge\n",
    "expected_columns = [\n",
    " 'Date',\n",
    " 'TempHighF',\n",
    " 'TempLowF',\n",
    " 'DewPointHighF',\n",
    " 'DewPointAvgF',\n",
    " 'DewPointLowF',\n",
    " 'HumidityHighPercent',\n",
    " 'HumidityAvgPercent',\n",
    " 'HumidityLowPercent',\n",
    " 'SeaLevelPressureHighInches',\n",
    " 'SeaLevelPressureAvgInches',\n",
    " 'SeaLevelPressureLowInches',\n",
    " 'VisibilityHighMiles',\n",
    " 'VisibilityAvgMiles',\n",
    " 'VisibilityLowMiles',\n",
    " 'WindHighMPH',\n",
    " 'WindAvgMPH',\n",
    " 'WindGustMPH',\n",
    " 'Snow',\n",
    " 'Fog',\n",
    " 'Rain',\n",
    " 'Thunderstorm']\n",
    "\n",
    "print(\"Expected columns vs Actual columns:\")\n",
    "print(f\"Expected: {len(expected_columns)} columns\")\n",
    "print(f\"Actual: {len(X.columns)} columns\")\n",
    "\n",
    "# Check if we have all expected columns\n",
    "missing_cols = set(expected_columns) - set(X.columns)\n",
    "extra_cols = set(X.columns) - set(expected_columns)\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"Missing columns: {missing_cols}\")\n",
    "if extra_cols:\n",
    "    print(f\"Extra columns: {extra_cols}\")\n",
    "if not missing_cols and not extra_cols:\n",
    "    print(\"✓ All columns match perfectly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, import `train_test_split` from `sklearn.model_selection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_test_split imported successfully!\n"
     ]
    }
   ],
   "source": [
    "#Your code here:\n",
    "# Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"train_test_split imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have split the data to predictor and response variables and imported the `train_test_split()` function, split `X` and `y` into `X_train`, `X_test`, `y_train`, and `y_test`. 80% of the data should be in the training set and 20% in the test set. `train_test_split()` reference can be accessed [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "\n",
    "Enter your code in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split completed!\n",
      "Training set size: 1055 samples (80.0%)\n",
      "Test set size: 264 samples (20.0%)\n",
      "Total samples: 1319\n",
      "\n",
      "X_train shape: (1055, 22)\n",
      "X_test shape: (264, 22)\n",
      "y_train shape: (1055,)\n",
      "y_test shape: (264,)\n"
     ]
    }
   ],
   "source": [
    "#Your code here:\n",
    "# Split X and y into training and test sets\n",
    "# 80% training, 20% test (test_size=0.2)\n",
    "# random_state for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data split completed!\")\n",
    "print(f\"Training set size: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "\n",
    "print(f\"\\nX_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification of train/test split:\n",
      "Original data: 1319 samples\n",
      "Train + Test: 1319 samples\n",
      "Data preserved: True\n",
      "\n",
      "Target variable (TempAvgF) statistics:\n",
      "Training set:\n",
      "count    1055.000000\n",
      "mean       70.628436\n",
      "std        13.966018\n",
      "min        29.000000\n",
      "25%        62.000000\n",
      "50%        73.000000\n",
      "75%        83.000000\n",
      "max        93.000000\n",
      "Name: TempAvgF, dtype: float64\n",
      "\n",
      "Test set:\n",
      "count    264.000000\n",
      "mean      70.700758\n",
      "std       14.387542\n",
      "min       29.000000\n",
      "25%       61.500000\n",
      "50%       73.000000\n",
      "75%       82.250000\n",
      "max       92.000000\n",
      "Name: TempAvgF, dtype: float64\n",
      "\n",
      "Original set:\n",
      "count    1319.000000\n",
      "mean       70.642911\n",
      "std        14.045904\n",
      "min        29.000000\n",
      "25%        62.000000\n",
      "50%        73.000000\n",
      "75%        83.000000\n",
      "max        93.000000\n",
      "Name: TempAvgF, dtype: float64\n",
      "\n",
      "Sample of training data (X_train):\n",
      "        Date  TempHighF  TempLowF  DewPointHighF  DewPointAvgF  DewPointLowF  \\\n",
      "598   735821        105        75           70.0         69.25          67.5   \n",
      "1213  736436         80        63           67.0         65.00          57.0   \n",
      "209   735432         78        72           74.0         71.00          68.0   \n",
      "538   735761         93        75           75.0         73.00          71.0   \n",
      "140   735363         91        60           66.0         62.00          58.0   \n",
      "\n",
      "      HumidityHighPercent  HumidityAvgPercent  HumidityLowPercent  \\\n",
      "598                  77.5                52.5                27.5   \n",
      "1213                 90.0                80.0                69.0   \n",
      "209                 100.0                87.0                74.0   \n",
      "538                  88.0                70.0                52.0   \n",
      "140                  97.0                71.0                44.0   \n",
      "\n",
      "      SeaLevelPressureHighInches  ...  VisibilityHighMiles  \\\n",
      "598                      29.9725  ...                 10.0   \n",
      "1213                     30.0500  ...                 10.0   \n",
      "209                      30.0100  ...                 10.0   \n",
      "538                      29.8700  ...                 10.0   \n",
      "140                      29.9200  ...                 10.0   \n",
      "\n",
      "      VisibilityAvgMiles  VisibilityLowMiles  WindHighMPH  WindAvgMPH  \\\n",
      "598                 10.0                10.0         13.5         4.5   \n",
      "1213                10.0                 6.0         16.0         5.0   \n",
      "209                  7.0                 1.0         14.0         3.0   \n",
      "538                 10.0                10.0         13.0         6.0   \n",
      "140                 10.0                 5.0         16.0         6.0   \n",
      "\n",
      "      WindGustMPH  Snow  Fog  Rain  Thunderstorm  \n",
      "598          20.0     0    0     0             0  \n",
      "1213         26.0     0    0     1             1  \n",
      "209          27.0     0    0     1             1  \n",
      "538          20.0     0    0     0             0  \n",
      "140          23.0     0    0     0             0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Corresponding target values (y_train):\n",
      "598     90\n",
      "1213    72\n",
      "209     75\n",
      "538     84\n",
      "140     76\n",
      "Name: TempAvgF, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify the split worked correctly\n",
    "print(\"Verification of train/test split:\")\n",
    "\n",
    "# Check that we didn't lose any data\n",
    "total_train_test = len(X_train) + len(X_test)\n",
    "print(f\"Original data: {len(X)} samples\")\n",
    "print(f\"Train + Test: {total_train_test} samples\")\n",
    "print(f\"Data preserved: {total_train_test == len(X)}\")\n",
    "\n",
    "# Check target variable distribution\n",
    "print(f\"\\nTarget variable (TempAvgF) statistics:\")\n",
    "print(\"Training set:\")\n",
    "print(y_train.describe())\n",
    "print(\"\\nTest set:\")\n",
    "print(y_test.describe())\n",
    "print(\"\\nOriginal set:\")\n",
    "print(y.describe())\n",
    "\n",
    "# Show sample of training data\n",
    "print(f\"\\nSample of training data (X_train):\")\n",
    "print(X_train.head())\n",
    "print(f\"\\nCorresponding target values (y_train):\")\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional verification:\n",
      "Missing values in X_train: 0\n",
      "Missing values in X_test: 0\n",
      "Missing values in y_train: 0\n",
      "Missing values in y_test: 0\n",
      "Index overlap between train and test: 0 (should be 0)\n",
      "\n",
      "Date range in training set: 735223 to 736541\n",
      "Date range in test set: 735246 to 736536\n"
     ]
    }
   ],
   "source": [
    "# Additional checks to ensure everything is correct\n",
    "print(\"Additional verification:\")\n",
    "\n",
    "# Check for any missing values in the splits\n",
    "print(f\"Missing values in X_train: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in X_test: {X_test.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in y_train: {y_train.isnull().sum()}\")\n",
    "print(f\"Missing values in y_test: {y_test.isnull().sum()}\")\n",
    "\n",
    "# Verify the indices are different (no overlap)\n",
    "train_indices = set(X_train.index)\n",
    "test_indices = set(X_test.index)\n",
    "overlap = train_indices.intersection(test_indices)\n",
    "print(f\"Index overlap between train and test: {len(overlap)} (should be 0)\")\n",
    "\n",
    "# Check the date range in both sets\n",
    "if 'Date' in X_train.columns:\n",
    "    print(f\"\\nDate range in training set: {X_train['Date'].min()} to {X_train['Date'].max()}\")\n",
    "    print(f\"Date range in test set: {X_test['Date'].min()} to {X_test['Date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Congratulations! Now you have finished the preparation of the dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 1\n",
    "\n",
    "#### While the above is the common practice to prepare most datasets, when it comes to time series data, we sometimes do not want to randomly select rows from our dataset.\n",
    "\n",
    "This is because many time series algorithms rely on observations having equal time distances between them. In such cases, we typically select the majority of rows as the test data and the last few rows as the training data. We don't use `train_test_split()` to select the train/test data because it returns random selections.\n",
    "\n",
    "In the following cell, compute the number of rows that account for 80% of our data and round it to the next integer. Assign this number to `ts_rows`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in dataset: 1319\n",
      "80% of data: 1055.2\n",
      "Rounded up (ts_rows): 1056\n",
      "Training set will be: 1056 rows (80.1%)\n",
      "Test set will be: 263 rows (19.9%)\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "import math\n",
    "\n",
    "# Compute the number of rows that account for 80% of our data\n",
    "total_rows = len(austin_fixed)\n",
    "ts_rows = math.ceil(total_rows * 0.8)  # Round up to next integer\n",
    "\n",
    "print(f\"Total rows in dataset: {total_rows}\")\n",
    "print(f\"80% of data: {total_rows * 0.8}\")\n",
    "print(f\"Rounded up (ts_rows): {ts_rows}\")\n",
    "print(f\"Training set will be: {ts_rows} rows ({ts_rows/total_rows*100:.1f}%)\")\n",
    "print(f\"Test set will be: {total_rows - ts_rows} rows ({(total_rows - ts_rows)/total_rows*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the first `ts_rows` rows of `X` to `X_ts_train` and the remaining rows to `X_ts_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series split for X (features):\n",
      "X_ts_train shape: (1056, 22)\n",
      "X_ts_test shape: (263, 22)\n",
      "Total samples: 1319 (should equal 1319)\n",
      "No data loss: True\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "# Assign the first ts_rows rows of X to X_ts_train and the remaining rows to X_ts_test\n",
    "X_ts_train = X.iloc[:ts_rows]  # First ts_rows rows\n",
    "X_ts_test = X.iloc[ts_rows:]   # Remaining rows\n",
    "\n",
    "print(\"Time series split for X (features):\")\n",
    "print(f\"X_ts_train shape: {X_ts_train.shape}\")\n",
    "print(f\"X_ts_test shape: {X_ts_test.shape}\")\n",
    "\n",
    "# Verify we didn't lose any data\n",
    "print(f\"Total samples: {len(X_ts_train) + len(X_ts_test)} (should equal {total_rows})\")\n",
    "print(f\"No data loss: {len(X_ts_train) + len(X_ts_test) == total_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the first `ts_rows` rows of `y` to `y_ts_train` and the remaining rows to `y_ts_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series split for y (target):\n",
      "y_ts_train shape: (1056,)\n",
      "y_ts_test shape: (263,)\n",
      "Total samples: 1319 (should equal 1319)\n",
      "No data loss: True\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "# Assign the first ts_rows rows of y to y_ts_train and the remaining rows to y_ts_test\n",
    "y_ts_train = y.iloc[:ts_rows]  # First ts_rows rows\n",
    "y_ts_test = y.iloc[ts_rows:]   # Remaining rows\n",
    "\n",
    "print(\"Time series split for y (target):\")\n",
    "print(f\"y_ts_train shape: {y_ts_train.shape}\")\n",
    "print(f\"y_ts_test shape: {y_ts_test.shape}\")\n",
    "\n",
    "# Verify we didn't lose any data\n",
    "print(f\"Total samples: {len(y_ts_train) + len(y_ts_test)} (should equal {total_rows})\")\n",
    "print(f\"No data loss: {len(y_ts_train) + len(y_ts_test) == total_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification of time series split:\n",
      "Training set date range:\n",
      "  From: 2013-12-21\n",
      "  To:   2016-11-10\n",
      "Test set date range:\n",
      "  From: 2016-11-11\n",
      "  To:   2017-07-31\n",
      "\n",
      "Chronological order check:\n",
      "Latest training date: 2016-11-10\n",
      "Earliest test date: 2016-11-11\n",
      "Proper time series order: True\n"
     ]
    }
   ],
   "source": [
    "# Let's verify our time series split makes chronological sense\n",
    "print(\"Verification of time series split:\")\n",
    "\n",
    "# Check the date ranges\n",
    "if 'Date' in X.columns:\n",
    "    print(f\"Training set date range:\")\n",
    "    print(f\"  From: {datetime.date.fromordinal(int(X_ts_train['Date'].min()))}\")\n",
    "    print(f\"  To:   {datetime.date.fromordinal(int(X_ts_train['Date'].max()))}\")\n",
    "    \n",
    "    print(f\"Test set date range:\")\n",
    "    print(f\"  From: {datetime.date.fromordinal(int(X_ts_test['Date'].min()))}\")\n",
    "    print(f\"  To:   {datetime.date.fromordinal(int(X_ts_test['Date'].max()))}\")\n",
    "    \n",
    "    # Verify chronological order\n",
    "    train_max_date = X_ts_train['Date'].max()\n",
    "    test_min_date = X_ts_test['Date'].min()\n",
    "    print(f\"\\nChronological order check:\")\n",
    "    print(f\"Latest training date: {datetime.date.fromordinal(int(train_max_date))}\")\n",
    "    print(f\"Earliest test date: {datetime.date.fromordinal(int(test_min_date))}\")\n",
    "    print(f\"Proper time series order: {train_max_date < test_min_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPARISON: Random Split vs Time Series Split\n",
      "============================================================\n",
      "RANDOM SPLIT (from Challenge 5):\n",
      "X_train shape: (1055, 22)\n",
      "X_test shape: (264, 22)\n",
      "Train date range: 2013-12-21 to 2017-07-31\n",
      "Test date range: 2014-01-13 to 2017-07-26\n",
      "\n",
      "TIME SERIES SPLIT (Bonus Challenge):\n",
      "X_ts_train shape: (1056, 22)\n",
      "X_ts_test shape: (263, 22)\n",
      "Train date range: 2013-12-21 to 2016-11-10\n",
      "Test date range: 2016-11-11 to 2017-07-31\n"
     ]
    }
   ],
   "source": [
    "# Compare the two splitting approaches\n",
    "print(\"=\"*60)\n",
    "print(\"COMPARISON: Random Split vs Time Series Split\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"RANDOM SPLIT (from Challenge 5):\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "if 'Date' in X_train.columns:\n",
    "    print(f\"Train date range: {datetime.date.fromordinal(int(X_train['Date'].min()))} to {datetime.date.fromordinal(int(X_train['Date'].max()))}\")\n",
    "    print(f\"Test date range: {datetime.date.fromordinal(int(X_test['Date'].min()))} to {datetime.date.fromordinal(int(X_test['Date'].max()))}\")\n",
    "\n",
    "print(f\"\\nTIME SERIES SPLIT (Bonus Challenge):\")\n",
    "print(f\"X_ts_train shape: {X_ts_train.shape}\")\n",
    "print(f\"X_ts_test shape: {X_ts_test.shape}\")\n",
    "if 'Date' in X_ts_train.columns:\n",
    "    print(f\"Train date range: {datetime.date.fromordinal(int(X_ts_train['Date'].min()))} to {datetime.date.fromordinal(int(X_ts_train['Date'].max()))}\")\n",
    "    print(f\"Test date range: {datetime.date.fromordinal(int(X_ts_test['Date'].min()))} to {datetime.date.fromordinal(int(X_ts_test['Date'].max()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample from TIME SERIES TRAINING set (earliest data):\n",
      "     Date  TempHighF  TempLowF\n",
      "0  735223         74        45\n",
      "1  735224         56        39\n",
      "2  735225         58        32\n",
      "3  735226         61        31\n",
      "4  735227         58        41\n",
      "\n",
      "Sample from TIME SERIES TEST set (latest data):\n",
      "        Date  TempHighF  TempLowF\n",
      "1056  736279         74        55\n",
      "1057  736280         77        57\n",
      "1058  736281         76        54\n",
      "1059  736282         82        56\n",
      "1060  736283         86        59\n",
      "\n",
      "Target variable statistics (Time Series Split):\n",
      "Training set (y_ts_train):\n",
      "count    1056.000000\n",
      "mean       70.697917\n",
      "std        14.248527\n",
      "min        29.000000\n",
      "25%        61.000000\n",
      "50%        73.000000\n",
      "75%        83.000000\n",
      "max        92.000000\n",
      "Name: TempAvgF, dtype: float64\n",
      "\n",
      "Test set (y_ts_test):\n",
      "count    263.000000\n",
      "mean      70.422053\n",
      "std       13.224739\n",
      "min       29.000000\n",
      "25%       62.000000\n",
      "50%       71.000000\n",
      "75%       80.000000\n",
      "max       93.000000\n",
      "Name: TempAvgF, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Show samples from each time series set\n",
    "print(\"\\nSample from TIME SERIES TRAINING set (earliest data):\")\n",
    "print(X_ts_train[['Date', 'TempHighF', 'TempLowF']].head())\n",
    "\n",
    "print(\"\\nSample from TIME SERIES TEST set (latest data):\")\n",
    "print(X_ts_test[['Date', 'TempHighF', 'TempLowF']].head())\n",
    "\n",
    "# Show target variable statistics for time series split\n",
    "print(f\"\\nTarget variable statistics (Time Series Split):\")\n",
    "print(\"Training set (y_ts_train):\")\n",
    "print(y_ts_train.describe())\n",
    "print(\"\\nTest set (y_ts_test):\")\n",
    "print(y_ts_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BONUS CHALLENGE 1 COMPLETED!\n",
      "============================================================\n",
      "✓ Time series training set: 1056 samples\n",
      "✓ Time series test set: 263 samples\n",
      "✓ Total samples preserved: 1319 = 1319\n",
      "✓ No index overlap: 0 overlapping indices\n",
      "✓ Chronological order maintained\n",
      "✓ Training on historical data, testing on recent data\n",
      "✓ Split point: 2016-11-10\n"
     ]
    }
   ],
   "source": [
    "# Final verification\n",
    "print(\"=\"*60)\n",
    "print(\"BONUS CHALLENGE 1 COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verify no index overlap\n",
    "ts_train_indices = set(X_ts_train.index)\n",
    "ts_test_indices = set(X_ts_test.index)\n",
    "ts_overlap = ts_train_indices.intersection(ts_test_indices)\n",
    "\n",
    "print(f\"✓ Time series training set: {len(X_ts_train)} samples\")\n",
    "print(f\"✓ Time series test set: {len(X_ts_test)} samples\")\n",
    "print(f\"✓ Total samples preserved: {len(X_ts_train) + len(X_ts_test)} = {total_rows}\")\n",
    "print(f\"✓ No index overlap: {len(ts_overlap)} overlapping indices\")\n",
    "print(f\"✓ Chronological order maintained\")\n",
    "print(f\"✓ Training on historical data, testing on recent data\")\n",
    "\n",
    "# Show the exact split point\n",
    "split_date = datetime.date.fromordinal(int(X_ts_train['Date'].max()))\n",
    "print(f\"✓ Split point: {split_date}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
